{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Extra Experiment.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnmahir/best-fyp/blob/main/Extra_Experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c_JNq8HtGTFU"
      },
      "source": [
        "#**Import Libraries**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjtiRu3dCtTg"
      },
      "source": [
        "# Google Drive\n",
        "from google.colab import drive\n",
        "# General\n",
        "import math\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import keras\n",
        "import itertools\n",
        "import random as python_random\n",
        "# Keras Library\n",
        "from keras.models import Sequential\n",
        "from keras import layers\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten\n",
        "from keras.layers import Convolution2D, MaxPool2D\n",
        "from keras.models import Model\n",
        "from keras import backend as Kbackend\n",
        "from keras.preprocessing import image\n",
        "# ScikitLearn\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import sklearn.metrics as metrics\n",
        "# Others\n",
        "import time\n",
        "import datetime\n",
        "import os\n",
        "\n",
        "print(\"Keras version: \", keras.__version__)\n",
        "print(\"TensorFlow version:\", tf.__version__)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hGPQTfele8cr"
      },
      "source": [
        "# Check GPU. With Colab Pro you have priority access to our fastest GPUs. For example, you may get a T4 or P100 GPU at times when most users of standard Colab receive a slower K80 GPU. You can see what GPU you've been assigned at any time by executing the following cell.\r\n",
        "gpu_info = !nvidia-smi\r\n",
        "gpu_info = '\\n'.join(gpu_info)\r\n",
        "if gpu_info.find('failed') >= 0:\r\n",
        "  print('Select the Runtime > \"Change runtime type\" menu to enable a GPU accelerator, ')\r\n",
        "  print('and then re-execute this cell.')\r\n",
        "else:\r\n",
        "  print(gpu_info)\r\n",
        "# In order to use a GPU with your notebook, select the Runtime > Change runtime type menu, and then set the hardware accelerator dropdown to GPU."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4O-p995K0b0"
      },
      "source": [
        "# **Initialize Functions**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMy7-6miwQsJ"
      },
      "source": [
        "# Tools"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QjG_Hxg4wPlN"
      },
      "source": [
        "############################\n",
        "# Solving class imbalance\n",
        "############################\n",
        "def get_freq_data(generator):\n",
        "  class_data_labels = generator.classes\n",
        "  total_class = len(IMAGE_CLASSES)\n",
        "  freq_out = []\n",
        "\n",
        "  for i in range(total_class):\n",
        "    total_label_i = 0\n",
        "    for ele in class_data_labels:\n",
        "      if ele == i:\n",
        "        total_label_i += 1\n",
        "    freq_out.append(total_label_i)\n",
        "  \n",
        "  print(\"Total number of class is:\", total_class, generator.class_indices)\n",
        "  print(\"Total image in generator is: \", freq_out)\n",
        "  return freq_out\n",
        "############################\n",
        "# Display training and validation curve\n",
        "############################\n",
        "def display_training_curves(training, validation, title, subplot):\n",
        "  ax = plt.subplot(subplot)\n",
        "  ax.plot(training)\n",
        "  ax.plot(validation)\n",
        "  ax.set_title('Model '+ title)\n",
        "  ax.set_ylabel(title)\n",
        "  ax.set_xlabel('epoch')\n",
        "  ax.legend(['Training', 'Validation'])\n",
        "\n",
        "############################\n",
        "# Display confusion matrix\n",
        "############################\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues, subplot = 121):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    \n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "        cm = np.round(cm,2)\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "    plt.subplot(subplot)\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))  # Count number of classes for x & y axis lable\n",
        "    plt.xticks(tick_marks, classes, rotation=45) # x-axis label rotated 45 degree\n",
        "    plt.yticks(tick_marks, classes) # y-axis label\n",
        "    \n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "            horizontalalignment=\"center\",\n",
        "            color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "  \n",
        "############################\n",
        "# Show generated image\n",
        "############################\n",
        "def show_image_generated(generator, index, img_size):\n",
        "  x, y = generator.__getitem__(index)\n",
        "  img_plt = math.ceil(math.sqrt(BATCH_SIZE))\n",
        "  grid_plt = str(img_plt)+str(img_plt)+str(1)\n",
        "  plt.figure(1, figsize = (img_size,img_size))\n",
        "  for i in range(BATCH_SIZE):\n",
        "    plt.subplot(img_plt,img_plt,i+1)\n",
        "    plt.imshow(x[i])\n",
        "    plt.title(IMAGE_CLASSES[np.where(y[i] == 1.)[0][0]], fontsize = 2+img_size, pad = 0)\n",
        "    plt.axis('off')\n",
        "  plt.show()\n",
        "\n",
        "###########################\n",
        "# Show augmented image\n",
        "###########################\n",
        "# This function will plot images in the form of a grid with 1 row and 5 columns where images are placed in each column.\n",
        "def plot_augmented_images(img_generator, num, index_i = 0, index_j = 0):\n",
        "    images_arr = [img_generator[index_i][0][index_j] for i in range(num)]\n",
        "    fig, axes = plt.subplots(1, num, figsize=(20,20))\n",
        "    axes = axes.flatten()\n",
        "    for img, ax in zip(images_arr, axes):\n",
        "        ax.axis('off')\n",
        "        ax.imshow(img)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "############################\n",
        "# Show all prediction images\n",
        "############################\n",
        "def show_all_prediction_image(class_dir, generator, true_labels, pred_labels):\n",
        "  image_freq = get_freq_data(generator)\n",
        "  correct_pred = []\n",
        "  wrong_pred = []\n",
        "  for i in range(len(IMAGE_CLASSES)):\n",
        "    correct_num = 0\n",
        "    wrong_num = 0\n",
        "    for j in range(len(true_labels)):\n",
        "      if true_labels[j] == i:\n",
        "        if true_labels[j] == pred_labels[j]:\n",
        "          correct_num += 1\n",
        "        else:\n",
        "          wrong_num += 1\n",
        "    correct_pred.append(correct_num)\n",
        "    wrong_pred.append(wrong_num)\n",
        "\n",
        "  print('Folder names:' + str(sorted(os.listdir(class_dir))))\n",
        "  print('Correctly predicted:',correct_pred)\n",
        "  print('Wrongly predicted:',wrong_pred)\n",
        "\n",
        "  label_index_show = 0\n",
        "  file_name = []\n",
        "\n",
        "\n",
        "  \n",
        "  disp_col = 8\n",
        "  for i, class_f in enumerate(sorted(os.listdir(class_dir))):\n",
        "    img_dir = class_dir + '/' + class_f\n",
        "    display_row = math.ceil(image_freq[i]/disp_col)\n",
        "    batch_holder = np.zeros((image_freq[i], IMAGE_WIDTH, IMAGE_HEIGHT, 3))\n",
        "    print('========================================================================')\n",
        "    print('True Class:', class_f)\n",
        "    print('Total images:', image_freq[i],'| Correctly predicted:',correct_pred[i],'| Wrongly predicted:',wrong_pred[i])\n",
        "    print('========================================================================')\n",
        "    for j,img in enumerate(sorted(os.listdir(img_dir))):\n",
        "      file_name.append(img)\n",
        "      img = image.load_img(os.path.join(img_dir,img), target_size=(IMAGE_WIDTH,IMAGE_HEIGHT))\n",
        "      batch_holder[j, :] = img\n",
        "\n",
        "    plt.figure(1, figsize = (disp_col*1.9,display_row*2.2))\n",
        "\n",
        "    for j,img in enumerate(batch_holder):\n",
        "      title = str(file_name[label_index_show]) + '\\nP: ' + IMAGE_CLASSES[pred_labels[label_index_show]]\n",
        "      plt.subplot(display_row, disp_col, j+1)\n",
        "      if true_labels[label_index_show] == pred_labels[label_index_show]:\n",
        "        plt.title(title)\n",
        "      else:\n",
        "        plt.title(title,color = 'red')\n",
        "      plt.axis('off')\n",
        "      plt.imshow(img/256.)\n",
        "      label_index_show += 1\n",
        "      \n",
        "    plt.show()\n",
        "\n",
        "############################\n",
        "# Get input image for pre-trained model\n",
        "############################\n",
        "def get_pretrained_model_input_size(MODEL = 'None'):\n",
        "  if MODEL == 'Xception' or MODEL == 'InceptionV3' or MODEL == 'InceptionResNetV2':\n",
        "    return (299, 299, 3)\n",
        "  elif MODEL == 'VGG16' or MODEL == 'VGG19' or MODEL == 'ResNet50V2' or MODEL == 'ResNet101V2' or MODEL == 'ResNet152V2' or MODEL == 'MobileNetV2' or MODEL == 'DenseNet121' or MODEL == 'DenseNet169' or MODEL == 'DenseNet201' or MODEL == 'NASNetMobile':\n",
        "    return (224, 224, 3)\n",
        "  elif MODEL == 'NASNetLarge':\n",
        "    return (331, 331, 3)\n",
        "  else:\n",
        "    print(\"Invalid model name/ not defined\")\n",
        "    return (0,0,0)\n",
        "############################\n",
        "# Convert File size unit\n",
        "############################\n",
        "def convert_file_size_unit(size_in_bytes, unit):\n",
        "   if unit == 'kB':\n",
        "       return size_in_bytes/1024\n",
        "   elif unit == 'MB':\n",
        "       return size_in_bytes/(1024*1024)\n",
        "   elif unit == 'GB':\n",
        "       return size_in_bytes/(1024*1024*1024)\n",
        "   else:\n",
        "       return size_in_bytes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWr5BoRUu91K"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9DAdDNLpK67S"
      },
      "source": [
        "############################\n",
        "# Training data generator\n",
        "############################\n",
        "def get_train_generator():\n",
        "  print(\"Getting train generator...\")\n",
        "  image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      rotation_range = 90,\n",
        "      vertical_flip = True,\n",
        "      horizontal_flip = True,\n",
        "      fill_mode = 'reflect'\n",
        "  )\n",
        "\n",
        "  generator = image_generator.flow_from_directory(\n",
        "      batch_size = BATCH_SIZE,\n",
        "      directory = train_path,\n",
        "      shuffle = True,             # Shuffle input after each epoch\n",
        "      target_size = (IMAGE_WIDTH, IMAGE_HEIGHT),   # Set image size to be [x]px by [y]px set in IMAGE_SIZE\n",
        "      class_mode = 'categorical',\n",
        "      seed = SEED,\n",
        "  )\n",
        "\n",
        "  return generator\n",
        "############################\n",
        "# Validation data generator\n",
        "############################\n",
        "def get_valid_generator():\n",
        "  print(\"Getting valid generator...\")\n",
        "  image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255\n",
        "  )\n",
        "\n",
        "  generator = image_generator.flow_from_directory(\n",
        "      batch_size = BATCH_SIZE,\n",
        "      directory = valid_path,\n",
        "      shuffle = False,             # Shuffle input after each epoch\n",
        "      target_size = (IMAGE_WIDTH, IMAGE_HEIGHT),   # Set image size to be [x]px by [y]px set in IMAGE_SIZE\n",
        "      class_mode = 'categorical',\n",
        "      seed = SEED,\n",
        "  )\n",
        "\n",
        "  return generator\n",
        "############################\n",
        "# Test data generator\n",
        "############################\n",
        "def get_test_generator():\n",
        "  print(\"Getting test generator...\")\n",
        "  image_generator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255\n",
        "  )\n",
        "\n",
        "  generator = image_generator.flow_from_directory(\n",
        "      batch_size = BATCH_SIZE,\n",
        "      directory = test_path,\n",
        "      shuffle = False,             # Shuffle input after each epoch\n",
        "      target_size = (IMAGE_WIDTH, IMAGE_HEIGHT),   # Set image size to be [x]px by [y]px set in IMAGE_SIZE\n",
        "      class_mode = 'categorical',\n",
        "      seed = SEED,\n",
        "  )\n",
        "\n",
        "  return generator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tI6wEkbs8vJo"
      },
      "source": [
        "# Model Development"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hxYrJyVsvJI"
      },
      "source": [
        "############################\n",
        "# Custom model\n",
        "############################\n",
        "def get_custom_model(print_summary = False):\n",
        "  model = Sequential()\n",
        "  model.add(Convolution2D(nb_filters, (5, 5), activation = 'relu', padding='same', input_shape=input_shape))\n",
        "  model.add(Convolution2D(nb_filters, (5, 5), activation = 'relu', padding='same'))\n",
        "  model.add(MaxPool2D(pool_size=pool_size))\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  model.add(Convolution2D(nb_filters*2, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(Convolution2D(nb_filters*2, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(Convolution2D(nb_filters*2, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(MaxPool2D(pool_size=pool_size))\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  model.add(Convolution2D(nb_filters*2, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(Convolution2D(nb_filters*2, (3, 3), activation='relu', padding='same'))\n",
        "  model.add(MaxPool2D(pool_size=pool_size))\n",
        "  model.add(Dropout(rate=0.25))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation='relu'))\n",
        "  model.add(Dropout(rate=0.5))\n",
        "  model.add(Dense(4, activation='softmax'))\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  if print_summary:\n",
        "    model.summary()\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0X0KuNlKNwcx"
      },
      "source": [
        "############################\n",
        "# Transfer learning model\n",
        "############################\n",
        "def get_pretrained_model(transfer_learning_model = 'None', weights = None, unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True):\n",
        "  ################ Choose Pre-trained model #########################\n",
        "  if transfer_learning_model == 'Xception':\n",
        "    selected_model = \"Xception pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.Xception(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "  \n",
        "  elif transfer_learning_model == 'VGG16':\n",
        "    selected_model = \"VGG16 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.VGG16(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "  \n",
        "  elif transfer_learning_model == 'VGG19':\n",
        "    selected_model = \"VGG19 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.VGG19(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'ResNet50V2':\n",
        "    selected_model = \"ResNet50V2 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.ResNet50V2(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "  \n",
        "  elif transfer_learning_model == 'ResNet101V2':\n",
        "    selected_model = \"ResNet101V2 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.ResNet101V2(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'ResNet152V2':\n",
        "    selected_model = \"ResNet152V2 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.ResNet152V2(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'InceptionV3':\n",
        "    selected_model = \"InceptionV3 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.InceptionV3(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'InceptionResNetV2':\n",
        "    selected_model = \"InceptionResNetV2 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.InceptionResNetV2(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'MobileNetV2':\n",
        "    selected_model = \"MobileNetV2 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.MobileNetV2(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'DenseNet121':\n",
        "    selected_model = \"DenseNet121 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.DenseNet121(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'DenseNet169':\n",
        "    selected_model = \"DenseNet169 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.DenseNet169(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'DenseNet201':\n",
        "    selected_model = \"DenseNet201 pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.DenseNet201(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'NASNetMobile':\n",
        "    selected_model = \"NASNetMobile pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.NASNetMobile(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "\n",
        "  elif transfer_learning_model == 'NASNetLarge':\n",
        "    selected_model = \"NASNetLarge pre-trained model selected\"\n",
        "    print(selected_model)\n",
        "    pretrained_model = tf.keras.applications.NASNetLarge(input_shape = (IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL), weights = weights, include_top=False)\n",
        "  \n",
        "  else:\n",
        "    print(\"Not defined / Does not exist\")\n",
        "    return 0\n",
        "  ##################################################################\n",
        "  # Freeze early layers\n",
        "  for layer in pretrained_model.layers:\n",
        "    if unfreeze_last_layer < len(pretrained_model.layers):\n",
        "      layer.trainable = False\n",
        "      unfreeze_last_layer += 1\n",
        "\n",
        "  # Print summary of pre-trained model\n",
        "  if print_summary:\n",
        "    pretrained_model.summary()\n",
        "    if unfreeze_last_layer > 0:\n",
        "      print(\"####################### UNFREEZED LAYER #########################\")\n",
        "      print(\"Layer            Trainable\")\n",
        "      for layer in pretrained_model.layers:\n",
        "        if layer.trainable == True:\n",
        "          sp = '      '[len(layer.name)-9:]\n",
        "          print(layer.name, sp, layer.trainable)\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(pretrained_model)\n",
        "\n",
        "  # Fine tuning our layers - you can add more if you want\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.4))\n",
        "\n",
        "  # Prediction layer\n",
        "  model.add(layers.Dense(len(IMAGE_CLASSES), activation = 'softmax'))\n",
        "\n",
        "  # Compile model\n",
        "  model.compile(\n",
        "      optimizer='adam',\n",
        "      loss = 'categorical_crossentropy',\n",
        "      metrics=['accuracy']\n",
        "  )\n",
        "\n",
        "  if print_fine_tuning_summary:\n",
        "    print(\"###################### AFTER FINE TUNING ########################\")\n",
        "    model.summary()\n",
        "    print(selected_model)\n",
        "\n",
        "  return model\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgWSGlMY8t3B"
      },
      "source": [
        "#**Mount**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enldOjQU8sZh"
      },
      "source": [
        "# Path where dataset is located\r\n",
        "drive.mount('/content/drive')\r\n",
        "dataset_path = '/content/drive/My Drive/FYP Stuff/Datasets/'\r\n",
        "dataset_name = 'Dataset 200EX'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sOCKSa2JNtUp"
      },
      "source": [
        "# **Training Preparation K = 1**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5EKDkLSxYfrx"
      },
      "source": [
        "K = ' K1'\n",
        "IMAGE_CLASSES = ['Normal','Grade I','Grade II','Grade III']         # Naming Classes (The names must be in the same order as in dataset folder (usually alphabetically))\n",
        "EPOCH = 100                      # Number of training epoch\n",
        "\n",
        "# Path\n",
        "train_path = dataset_path + dataset_name + K + '/Train'\n",
        "valid_path = dataset_path + dataset_name + K + '/Valid'    # Some literature use the term \"test set\" / \"valid set\" but it is actually a \"dev set\". This is the set that is iterated during training.\n",
        "test_path = dataset_path + dataset_name + K + '/Valid'  # Test set helps evaluate how good your final system is. It's ok not to have test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WRbFhUMwb69B"
      },
      "source": [
        "#**Training on DenseNet121**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h7MMWzhBb69B"
      },
      "source": [
        "MODEL = 'DenseNet121'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "my-jR4dWb69C"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vIc6Qiab69C"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5mWStAQb69C"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qAa4Tn9Ob69C"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kzp4vYv7b69C"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwWQKJ26b69D"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrJv2psNb69D"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HlsEuxFb69D"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "188v1t8Kb69D"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F2nul8rb69D"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6V41dJKb69D"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2IV04WQLb69E"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zc3MHsMWb69E"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "HYTSNEPqb69E"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUXZIFK_b787"
      },
      "source": [
        "#**Training on DenseNet169**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkMKE6k4b787"
      },
      "source": [
        "MODEL = 'DenseNet169'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ntK1gh5b787"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhoVsfnTb787"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0RRY16Ib788"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC07orfrb788"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eK96WqKCb788"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA4raGabb788"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5eLV-CdAb788"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0T8umctOb789"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S3jZ1zoIb789"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tiP8ZWuNb789"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0zx8O1bb789"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YNFlGaSRb789"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghFZ7g3ib78-"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "_DBCOXLnb78-"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rl5VqmzOb892"
      },
      "source": [
        "#**Training on DenseNet201**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF3WQJCUb893"
      },
      "source": [
        "MODEL = 'DenseNet201'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I_PWavobb893"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XSshM3Rhb894"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_vepFv0b894"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M_THHnYNb895"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s00j-Y7ub895"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a_8HckL9b896"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RtfpNzRCb896"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGyUqHkDb896"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gIVqrnemb896"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e6aSvabRb896"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXuu5Gzbb896"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OVtBPgMUb896"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UbBXHzXqb897"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "rl6JDCRvb897"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hs2qj82n8aDW"
      },
      "source": [
        "# **Training Preparation K = 2**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPifxS_e8aDk"
      },
      "source": [
        "K = ' K2'\n",
        "IMAGE_CLASSES = ['Normal','Grade I','Grade II','Grade III']         # Naming Classes (The names must be in the same order as in dataset folder (usually alphabetically))\n",
        "EPOCH = 100                      # Number of training epoch\n",
        "\n",
        "# Path\n",
        "train_path = dataset_path + dataset_name + K + '/Train'\n",
        "valid_path = dataset_path + dataset_name + K + '/Valid'    # Some literature use the term \"test set\" / \"valid set\" but it is actually a \"dev set\". This is the set that is iterated during training.\n",
        "test_path = dataset_path + dataset_name + K + '/Valid'  # Test set helps evaluate how good your final system is. It's ok not to have test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "77kVdcJL8aDl"
      },
      "source": [
        "#**Training on DenseNet121**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bqSTjYZh8aDm"
      },
      "source": [
        "MODEL = 'DenseNet121'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yco-Mqgp8aDn"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IDY8q_ug8aDn"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AbKVlcZV8aDo"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yamg7Msn8aDo"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzRPlvrn8aDo"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aC0DQZ578aDp"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uv4o6zOP8aDp"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E_0C5Tjz8aDq"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SNJb9u8aDq"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18biruWd8aDq"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0iSI0pWI8aDr"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7sBzVuD8aDr"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjRA-eB_8aDr"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "y9gg8DqK8aDs"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Ekxj0a_8aDs"
      },
      "source": [
        "#**Training on DenseNet169**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MYxpyDIu8aDs"
      },
      "source": [
        "MODEL = 'DenseNet169'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0OmE0Ei-8aDs"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OcDbNFWH8aDt"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ouarPPNc8aDt"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RvPCyWAg8aDt"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v3FCjoF8aDt"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y8ypDFNJ8aDu"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lcKkDzUu8aDu"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-uWXzUc8aDu"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yaFocBIw8aDu"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwBMt1Bu8aDv"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMkESggg8aDv"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fHOuOkd8aDv"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dq_XGJ2_8aDv"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CnKVAHwM8aDv"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z1LipNLS8aDw"
      },
      "source": [
        "#**Training on DenseNet201**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdBSHQAv8aDw"
      },
      "source": [
        "MODEL = 'DenseNet201'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-mwLuF-8aDw"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mc1-5GSs8aDw"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EutJjKrp8aDx"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8NGVFiR8aDx"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GYHxpC4H8aDx"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2zRWs6hX8aDx"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VgZTpCq88aDx"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "if2Wn-wi8aDy"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZjbMfr5m8aDy"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ODIALzb8aDy"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM3iYtBR8aDy"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ne-GJyG8aDy"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8GQI2ypG8aDz"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SoMyTXg38aDz"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U1mqQ6wF9Qi2"
      },
      "source": [
        "# **Training Preparation K = 3**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9MUBHNH19Qi9"
      },
      "source": [
        "K = ' K3'\n",
        "IMAGE_CLASSES = ['Normal','Grade I','Grade II','Grade III']         # Naming Classes (The names must be in the same order as in dataset folder (usually alphabetically))\n",
        "EPOCH = 100                      # Number of training epoch\n",
        "\n",
        "# Path\n",
        "train_path = dataset_path + dataset_name + K + '/Train'\n",
        "valid_path = dataset_path + dataset_name + K + '/Valid'    # Some literature use the term \"test set\" / \"valid set\" but it is actually a \"dev set\". This is the set that is iterated during training.\n",
        "test_path = dataset_path + dataset_name + K + '/Valid'  # Test set helps evaluate how good your final system is. It's ok not to have test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jO4SD6sw9Qi-"
      },
      "source": [
        "#**Training on DenseNet121**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TrgJNSAL9Qi-"
      },
      "source": [
        "MODEL = 'DenseNet121'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-GGg2Yn9Qi-"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OqW1Crlv9Qi-"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orMmGVzU9Qi-"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YIvbPG1H9Qi_"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE85B2sP9Qi_"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4nF2umuH9Qi_"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mf1InxfP9Qi_"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EaupqKcu9Qi_"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOVnMUYO9Qi_"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ASYfw7Bk9Qi_"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dYekNR6H9QjA"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgX-QlIY9QjA"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j2V1iqjN9QjA"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "g9rfKyBy9QjA"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmaQPZX69QjA"
      },
      "source": [
        "#**Training on DenseNet169**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMJKyB7i9QjA"
      },
      "source": [
        "MODEL = 'DenseNet169'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ft34d0B9QjA"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FyfYj_xr9QjA"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62KlVGn29QjA"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JiJ1RHVH9QjB"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nRp_Es3E9QjB"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uwH_Zngk9QjB"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF3j-3069QjB"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6_yRpuhH9QjB"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "skT6W2Jx9QjB"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5oXBcnoH9QjB"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBdlaghh9QjB"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Drt94rLD9QjB"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6OQf04r89QjB"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "fyVjxDPd9QjC"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPI3WNZn9QjC"
      },
      "source": [
        "#**Training on DenseNet201**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "njB7VCcM9QjC"
      },
      "source": [
        "MODEL = 'DenseNet201'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swfHXis99QjC"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vFAVU9u79QjC"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lP6uNcR09QjC"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74iyPtaj9QjC"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "icslwxA49QjC"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cncodg5r9QjC"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HQxesOJW9QjC"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3X-WmPfP9QjC"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4H1xial_9QjD"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B9fWtTOA9QjD"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zsFHFtKf9QjD"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s49ohawq9QjD"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Q1e4gEp9QjD"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "xTgnENq-9QjD"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pmMPmjpH9QjD"
      },
      "source": [
        "# **Training Preparation K = 4**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "baK8Il5q9QjD"
      },
      "source": [
        "K = ' K4'\n",
        "IMAGE_CLASSES = ['Normal','Grade I','Grade II','Grade III']         # Naming Classes (The names must be in the same order as in dataset folder (usually alphabetically))\n",
        "EPOCH = 100                      # Number of training epoch\n",
        "\n",
        "# Path\n",
        "train_path = dataset_path + dataset_name + K + '/Train'\n",
        "valid_path = dataset_path + dataset_name + K + '/Valid'    # Some literature use the term \"test set\" / \"valid set\" but it is actually a \"dev set\". This is the set that is iterated during training.\n",
        "test_path = dataset_path + dataset_name + K + '/Valid'  # Test set helps evaluate how good your final system is. It's ok not to have test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohaYzZoR9QjD"
      },
      "source": [
        "#**Training on DenseNet121**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NgJ3wBlx9QjD"
      },
      "source": [
        "MODEL = 'DenseNet121'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyEa5dEr9QjD"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUgH7tgQ9QjE"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YfjVGph9QjE"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7RqYhQ19QjE"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqBWzuDa9QjE"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IO9n9GG9QjE"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "riJiBtfL9QjE"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4GSwa1S9QjE"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMZ6YzKv9QjE"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XjD0-Ige9QjE"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1o9Dgi2g9QjE"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4NuNj7n69QjF"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fqe9zqGf9QjF"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "peuFNmya9QjF"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCGIRI5s9QjF"
      },
      "source": [
        "#**Training on DenseNet169**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXpbtLus9QjF"
      },
      "source": [
        "MODEL = 'DenseNet169'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c5wi6qFe9QjF"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJtnLTLt9QjF"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1GBxyiml9QjF"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rqoavX9B9QjF"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4TFRA4z9QjF"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LMeN0Azp9QjF"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8NOuOkQ39QjG"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOWZ2o1g9QjG"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MMlTgTWH9QjG"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z763s0dx9QjG"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8cLmFyad9QjG"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pdCOzlyE9QjG"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OCkJfyWO9QjG"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "uFqzfTXZ9QjG"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZS48VmUS9QjG"
      },
      "source": [
        "#**Training on DenseNet201**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lClK0WI89QjG"
      },
      "source": [
        "MODEL = 'DenseNet201'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2Sksf1L9QjG"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TpIOuSZr9QjH"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pXaKZUnl9QjH"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGMGBhF79QjH"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMYyVtZb9QjH"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Olf1vV-v9QjH"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79fyoloo9QjH"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-4pK_C5u9QjH"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWLLsmXG9QjH"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2erJV02J9QjH"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LH8pKEYI9QjH"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fy_NxUXp9QjH"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ApjAgzWo9QjI"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "X3xQSDKk9QjI"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jXGeYGgo9lM9"
      },
      "source": [
        "# **Training Preparation K = 5**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k7CZL8V_9lNB"
      },
      "source": [
        "K = ' K5'\n",
        "IMAGE_CLASSES = ['Normal','Grade I','Grade II','Grade III']         # Naming Classes (The names must be in the same order as in dataset folder (usually alphabetically))\n",
        "EPOCH = 100                      # Number of training epoch\n",
        "\n",
        "# Path\n",
        "train_path = dataset_path + dataset_name + K + '/Train'\n",
        "valid_path = dataset_path + dataset_name + K + '/Valid'    # Some literature use the term \"test set\" / \"valid set\" but it is actually a \"dev set\". This is the set that is iterated during training.\n",
        "test_path = dataset_path + dataset_name + K + '/Valid'  # Test set helps evaluate how good your final system is. It's ok not to have test set."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s_f7rR3v9lNB"
      },
      "source": [
        "#**Training on DenseNet121**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFZjLOsw9lNC"
      },
      "source": [
        "MODEL = 'DenseNet121'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-HTKXOI29lNC"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0m-XvxB59lNC"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAkRiXXJ9lNC"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hil-eJb29lNC"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9NfSy-Dt9lNC"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UJgWZVfF9lND"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CrPUUa59lND"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWik_oHp9lND"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQdW1vju9lND"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "96fvdVo69lND"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpYaVQbk9lND"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyFXho4J9lND"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89Jnzr0Y9lND"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "LiNu0HvZ9lNE"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgLr4NPP9lNE"
      },
      "source": [
        "#**Training on DenseNet169**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GJjBcgE9lNE"
      },
      "source": [
        "MODEL = 'DenseNet169'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3zAG7YNL9lNE"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X36ZGkOz9lNE"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Mqmt1W19lNE"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZ95EAo59lNE"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PiGeAsCp9lNE"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drKwfhkT9lNE"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vI32l3v59lNF"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zI6ZV6Na9lNF"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b5fo7_PC9lNF"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IA0dauQg9lNF"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_pPg2OJr9lNF"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-NBmC9mO9lNF"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqyOP1pu9lNF"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "qaERyFN99lNF"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F9N4OiUv9lNF"
      },
      "source": [
        "#**Training on DenseNet201**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "viqj6qey9lNF"
      },
      "source": [
        "MODEL = 'DenseNet201'              # Xception, VGG16, VGG19, InceptionResNetV2, ResNet50V2, ResNet101V2, ResNet152V2, InceptionV3, InceptionResNetV2, MobileNetV2, DenseNet121, DenseNet169, DenseNet201, NASNetMobile, NASNetLarge\n",
        "BATCH_SIZE = 64                 # Mini-batch size\n",
        "SEED = 2020                     # Fixed randomness (For reproducible result!)\n",
        "SAVE_MODEL_NAME = MODEL + '_' + dataset_name + K + '_awesome_model.h5'         # Name of the model to save after training\n",
        "python_random.seed(SEED)        # necessary for starting core Python generated random numbers in a well-defined state.\n",
        "np.random.seed(SEED)            # necessary for starting Numpy generated random numbers in a well-defined state.\n",
        "tf.random.set_seed(SEED)        # will make random number generation in the TensorFlow backend have a well-defined initial state.\n",
        "\n",
        "IMAGE_WIDTH, IMAGE_HEIGHT, IMAGE_CHANNEL = get_pretrained_model_input_size(MODEL)\n",
        "print(\"Training on\", MODEL)\n",
        "print(\"Input:\",IMAGE_WIDTH,'x',IMAGE_HEIGHT,'x',IMAGE_CHANNEL)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XOgONz849lNF"
      },
      "source": [
        "train_generator = get_train_generator()\n",
        "valid_generator = get_valid_generator()\n",
        "test_generator = get_test_generator()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mPcNKmIW9lNG"
      },
      "source": [
        "# Check number of image in each class\n",
        "train_freq = get_freq_data(train_generator)\n",
        "valid_freq = get_freq_data(valid_generator)\n",
        "total_freq = np.array(train_freq) + np.array(valid_freq)\n",
        "valid_data_freq = np.array(valid_freq)/total_freq\n",
        "print(\"Valid data Percentage:\",valid_data_freq)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwte-bJB9lNG"
      },
      "source": [
        "model = get_pretrained_model(MODEL, weights = 'imagenet', unfreeze_last_layer = 0, print_summary = False, print_fine_tuning_summary = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IL-jOlI99lNG"
      },
      "source": [
        "time_start = time.time()\n",
        "history = model.fit(\n",
        "    x = train_generator,\n",
        "    validation_data = valid_generator,\n",
        "    epochs = EPOCH,\n",
        "    verbose = 1,\n",
        "    steps_per_epoch = train_generator.samples / train_generator.batch_size ,\n",
        "    validation_steps = valid_generator.samples / valid_generator.batch_size\n",
        ")\n",
        "print(\"Training done. Evaluating...\")\n",
        "time_end = time.time()\n",
        "final_accuracy = history.history[\"val_accuracy\"][-5:]\n",
        "Training_Accuracy = model.evaluate(train_generator, steps=train_generator.samples / train_generator.batch_size)\n",
        "Validation_Accuracy = model.evaluate(test_generator, steps=valid_generator.samples / valid_generator.batch_size)\n",
        "print(\"Finish!\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pb74DLwF9lNG"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"Time taken:\", datetime.timedelta(seconds=(int(time_end - time_start))), \"(hh:mm:ss)\")\r\n",
        "print(\"The Model Accuracy for Train data is: \", \"{:.2%}\".format(Training_Accuracy[1]))\r\n",
        "print(\"The Model Accuracy for Validation data is: \", \"{:.2%}\".format(Validation_Accuracy[1]))\r\n",
        "print(\"FINAL VALIDATION ACCURACY MEAN-5: \", np.mean(final_accuracy))\r\n",
        "# Loss and Accuracy\r\n",
        "plt.subplots(figsize=(9,3.5))\r\n",
        "plt.tight_layout()\r\n",
        "display_training_curves(history.history['loss'], history.history['val_loss'], 'Loss', 121)\r\n",
        "display_training_curves(history.history['accuracy'], history.history['val_accuracy'], 'Accuracy', 122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1-8H4Zh9lNG"
      },
      "source": [
        "model.save(SAVE_MODEL_NAME) #Save"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nZTP6aUW9lNG"
      },
      "source": [
        "**Predict**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6MbMHQF9lNG"
      },
      "source": [
        "# True label\n",
        "true_labels = test_generator.classes  # Get label of valid_generator\n",
        "# Prediction label\n",
        "time_start = time.time()\n",
        "predictions = model.predict(x=test_generator, steps=len(test_generator),verbose = 0)\n",
        "time_end = time.time()\n",
        "pred_labels = np.argmax(predictions, axis=-1)\n",
        "pred_time = time_end - time_start"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rYB4pJpv9lNG"
      },
      "source": [
        "**Confusion Matrix**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NzCAY-H9lNG"
      },
      "source": [
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true=true_labels, y_pred=pred_labels)\n",
        "plt.subplots(figsize=(10,4))\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Confusion Matrix',normalize=False, subplot=121)\n",
        "plot_confusion_matrix(cm=cm, classes=IMAGE_CLASSES, title='Normalized Confusion Matrix',normalize=True, subplot=122)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ryktdy-19lNH"
      },
      "source": [
        "**Model Summary**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K86PrmWv9lNI"
      },
      "source": [
        "print(\"Trained on\", MODEL)\r\n",
        "print(\"For\", dataset_name, K)\r\n",
        "print(\"Training [Loss, Accuracy]: \", Training_Accuracy)\r\n",
        "print(\"Validaiton [Loss,Accuracy]: \", Validation_Accuracy)\r\n",
        "print(\"Prediction time: \", pred_time)\r\n",
        "print('Model Size:', convert_file_size_unit(os.stat(SAVE_MODEL_NAME).st_size,'MB'), 'MB')\r\n",
        "report = metrics.classification_report(y_true = true_labels, y_pred = pred_labels, target_names=IMAGE_CLASSES)\r\n",
        "print(report)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXEL95cS9lNI"
      },
      "source": [
        "**Show all images with predictions**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3DIMYhFH9lNI"
      },
      "source": [
        "show_all_prediction_image(test_path, test_generator, true_labels, pred_labels) # Argument:(Path of test dataset, test generator to generate image, true labels generated by test generator, predicted labels generated by model on test dataset)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}